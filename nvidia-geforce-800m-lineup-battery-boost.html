<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>NVIDIAs GeForce 800M Lineup for Laptops and Battery Boost -</title><meta name=robots content="index,follow,noarchive"><meta name=description content="Introducing NVIDIA’s GeForce 800M Lineup for Laptops Last month NVIDIA launched the first of many Maxwell parts to come with the desktop GTX 750 and GTX 750 Ti, which brought a new architecture to NVIDIA’s parts, but one that isn’t radically different from the previous generation’s Kepler. While the features may be largely the same, however, NVIDIA did come out with a renewed focus on efficiency. The result was roughly a doubling of performance per Watt, with the GTX 750 Ti being nearly twice as fast as the GTX 650 with only slightly higher power draw (and some of that most likely comes from the increased load on the rest of the system thanks to the higher frame rates)."><meta name=author content="Larita Shotwell"><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/app.css><link rel="preload stylesheet" as=style href=https://assets.cdnweb.info/hugo/paper/css/an-old-hope.min.css><script defer src=https://assets.cdnweb.info/hugo/paper/js/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=./theme.png><link rel=icon href=./favicon.ico><link rel=apple-touch-icon href=./apple-touch-icon.png><meta name=generator content="Hugo 0.98.0"><meta property="og:title" content="NVIDIAs GeForce 800M Lineup for Laptops and Battery Boost"><meta property="og:description" content="Last month NVIDIA launched the first of many Maxwell parts to come with the desktop GTX 750 and GTX 750 Ti, which brought a new architecture to NVIDIAs parts, but one that isnt radically different from the previous generations Kepler. While the features may be largely the same, however, NVIDIA did come out with a"><meta property="og:type" content="article"><meta property="og:url" content="/nvidia-geforce-800m-lineup-battery-boost.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-07-22T00:00:00+00:00"><meta property="article:modified_time" content="2024-07-22T00:00:00+00:00"><meta itemprop=name content="NVIDIAs GeForce 800M Lineup for Laptops and Battery Boost"><meta itemprop=description content="Last month NVIDIA launched the first of many Maxwell parts to come with the desktop GTX 750 and GTX 750 Ti, which brought a new architecture to NVIDIAs parts, but one that isnt radically different from the previous generations Kepler. While the features may be largely the same, however, NVIDIA did come out with a"><meta itemprop=datePublished content="2024-07-22T00:00:00+00:00"><meta itemprop=dateModified content="2024-07-22T00:00:00+00:00"><meta itemprop=wordCount content="1854"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="NVIDIAs GeForce 800M Lineup for Laptops and Battery Boost"><meta name=twitter:description content="Last month NVIDIA launched the first of many Maxwell parts to come with the desktop GTX 750 and GTX 750 Ti, which brought a new architecture to NVIDIAs parts, but one that isnt radically different from the previous generations Kepler. While the features may be largely the same, however, NVIDIA did come out with a"></head><body class=not-ready data-menu=true><header class=header><p class=logo><a class=site-name href=./index.html>JiveBlog</a><a class=btn-dark></a></p><script>let bodyClx=document.body.classList,btnDark=document.querySelector(".btn-dark"),sysDark=window.matchMedia("(prefers-color-scheme: dark)"),darkVal=localStorage.getItem("dark"),setDark=e=>{bodyClx[e?"add":"remove"]("dark"),localStorage.setItem("dark",e?"yes":"no")};setDark(darkVal?darkVal==="yes":sysDark.matches),requestAnimationFrame(()=>bodyClx.remove("not-ready")),btnDark.addEventListener("click",()=>setDark(!bodyClx.contains("dark"))),sysDark.addEventListener("change",e=>setDark(e.matches))</script><nav class=menu><a href=./sitemap.xml>Sitemap</a></nav></header><main class=main><article class=post-single><header class=post-title><p><time>Jul 22, 2024</time>
<span>Larita Shotwell</span></p><h1>NVIDIAs GeForce 800M Lineup for Laptops and Battery Boost</h1></header><section class=post-content><img src=https://cdn.statically.io/img/images.anandtech.com/doci/7834/NV_GTX_batteryboost-FINAL-smaller_678x452.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><h2>Introducing NVIDIA’s GeForce 800M Lineup for Laptops</h2><p>Last month NVIDIA launched the first of many Maxwell parts to come with the <a href=#>desktop GTX 750 and GTX 750 Ti</a>, which brought a new architecture to NVIDIA’s parts, but one that isn’t radically different from the previous generation’s Kepler. While the features may be largely the same, however, NVIDIA did come out with a renewed focus on efficiency. The result was roughly a doubling of performance per Watt, with the GTX 750 Ti being nearly twice as fast as the GTX 650 with only slightly higher power draw (and some of that most likely comes from the increased load on the rest of the system thanks to the higher frame rates). That renewed focus on efficiency is nice and all on the desktop, but in my opinion where it’s really going to pay dividends is when we get the mobile SKUs.</p><p>Today’s launch of the 800M series will give us the first taste of what’s to come, but unfortunately there are two minor issues. One is that we don’t have any 800M hardware in hand for testing (yet – we should get a notebook in the near future); the second problem is that, as is typically the case, 800M will be a mix of both Kepler and Maxwell parts. The Kepler parts aren’t straight recycling of existing SKUs, however, as NVIDIA has a new feature that’s coming out with all ofthe GTX 800M parts: Battery Boost. But before we get into the details of Battery Boost, let’s cover the various parts. Both "regular" (NVIDIA has dropped the "GT" branding of their mainsream parts) and GTX 800M chips are being announced today, though we of course still need these to show up in shipping laptops; we’ll start at the high-end and work our way down.</p><table align=center border=0 cellpadding=0 cellspacing=0 width=625><tbody readability=6><tr readability=2><td align=center class=contentwhite colspan=6><strong>NVIDIA GeForce GTX 800M Specifications</strong></td></tr><tr><td><strong>Product</strong></td><td><strong>GTX 880M</strong></td><td><strong>GTX 870M</strong></td><td><strong>GTX 860M</strong></td><td><strong>GTX 860M</strong></td><td><strong>GTX 850M</strong></td></tr><tr><td><strong>Process</strong></td><td>28nm</td><td>28nm</td><td>28nm</td><td>28nm</td><td>28nm</td></tr><tr><td><strong>Architecture</strong></td><td>Kepler</td><td>Kepler</td><td>Kepler</td><td>Maxwell</td><td>Maxwell</td></tr><tr><td><strong>Cores</strong></td><td>1536</td><td>1344</td><td>1152</td><td>640</td><td>640</td></tr><tr><td><strong>GPU Clock</strong></td><td>954 + Boost</td><td>941 + Boost</td><td>797 + Boost</td><td>1029 + Boost</td><td>876 + Boost</td></tr><tr><td><strong>RAM Clock</strong></td><td>2.5GHz</td><td>2.5GHz</td><td>2.5GHz</td><td>2.5GHz</td><td>2.5GHz</td></tr><tr><td><strong>RAM Interface</strong></td><td>256-bit</td><td>192-bit</td><td>128-bit</td><td>128-bit</td><td>128-bit</td></tr><tr><td><strong>RAM Technology</strong></td><td>GDDR5</td><td>GDDR5</td><td>GDDR5</td><td>GDDR5</td><td>GDDR5</td></tr><tr><td><strong>Maximum RAM</strong></td><td>4GB</td><td>3GB</td><td>2GB</td><td>2GB</td><td>2GB</td></tr><tr readability=10><td><strong>Features</strong></td><td>GPU Boost 2.0<br>Battery Boost<br>GameStream<br>ShadowPlay<br>Optimus<br>PhysX<br>CUDA<br>SLI<br>GeForce Experience</td><td>GPU Boost 2.0<br>Battery Boost<br>GameStream<br>ShadowPlay<br>Optimus<br>PhysX<br>CUDA<br>SLI<br>GeForce Experience</td><td>GPU Boost 2.0<br>Battery Boost<br>GameStream<br>ShadowPlay<br>Optimus<br>PhysX<br>CUDA<br>SLI<br>GeForce Experience</td><td>GPU Boost 2.0<br>Battery Boost<br>GameStream<br>ShadowPlay<br>Optimus<br>PhysX<br>CUDA<br>SLI<br>GeForce Experience</td><td>GPU Boost 2.0<br>Battery Boost<br>GameStream<br>ShadowPlay<br>Optimus<br>PhysX<br>CUDA<br>GeForce Experience</td></tr></tbody></table><p>At the top, the GTX 880M carries on from the successful GTX 780M, using a fully enabled GK104 chip with 1536 cores. The difference is that thanks to improvements in yields and other refinements, the GTX 880M will launch with a base clock of 954MHz, which is a pretty significant 20% bump over the 797MHz base clock of the GTX 780M. Otherwise, the only real change will be support for Battery Boost. This is really the only chip where we won’t see any major performance improvement relative to the 700M part – we get a theoretical 20% shader performance increase and that’s about it.</p><p>GTX 870M follows a slightly different pattern, using the same GK104 core but with one SMX disabled, leaving us with 1344 cores. Along with the loss of one SMX, the GTX 870M cuts the memory interface down to 192-bits. (Interestingly, this is the same core count as the GTX 775M found in Apple’s iMac only with a 192-bit memory interface, but to my knowledge the GTX 775M never shipped in a notebook.) The previous generation 770M only had 960 cores running at 811MHz + Boost, so overall the 870M should provide a significant boost in performance relative to the previous generation – around 62% more shader processing power and 25% more memory bandwidth as well!</p><p>Where things get a little [*cough*] interesting is when we get to the GTX 860M. As we’ve seen in the past, NVIDIA will have two different overlapping models of the 860M available, and they’re really not very similar (though pure performance will probably be pretty close). On the one hand, the Kepler-based 860M will use GK104 with yet another SMX and a memory channel disabled, giving us 1152 cores running at 797MHz + Boost and a 128-bit memory interface. This will probably result in performance relatively close to the previous generation GTX 770M (slightly higher shader performance but slightly less memory bandwidth).</p><p>The second GTX 860M will be a completely new Maxwell part, using the same GM107 as the desktop GTX 750/750 Ti with all SMX units active. That gives us 640 cores running at 1029MHz + Boost, which interestingly is faster than the base clock of the desktop GTX 750 Ti (1020MHz). Memory bandwidth doesn’t quite keep up with the desktop card, and of course overclocking is something that will almost certainly result in higher performance potential on desktops, but in general the Maxwell GTX 860M should perform very much like the GTX 750 Ti – and likely at a lower power envelope as well. Even if both GTX 860M parts deliver a similar level of performance, the Maxwell variant should do so while using less power, so that's the one I'd recommend. NVIDIA states that the 860M will be around 40% faster than the GTX 760M.</p><p>Finally, the last GTX part being launched today is the GTX 850M. Yes, that’s right: the “x50M” has now been moved from the (now defunct) GT class to the GTX class. This is partly being done in order to make the GTX 850M look better (i.e. marketing), but it’s also being done as a way to segment software feature sets – as we’ll see in a moment, the mainstream 800M GPUs do not support GameStream or ShadowPlay. Also note that the GTX 850M is the only GTX part that does not support SLI, as that feature is only present in the GTX 860M and above. (And while I’m discussing the Features aspect, GFE is my abbreviation for “GeForce Experience”.) There’s a bit more marketing as well, as NVIDIA compares the performance of the new GTX 850M with the previous generation GT 750M in their slides, where perhaps a better comparison would be the GTX 760M with the GTX 765M going up against the GTX 860M. It’s not particularly important in the grand scheme of things, however.</p><p>Moving past the naming aspect of the GTX 850M, the specifications are basically the same as the Maxwell GTX 860M, only with a lower core clock of 876MHz. One nice benefit of moving to the GTX class is that the 850M will require the use of GDDR5. With previous generation mobile GPUs, NVIDIA often allowed OEMs to use either GDDR5 or DDR3. While in theory the gaming experience between the who would be “similar”, that really depends on the game and the settings. I know from experience that in some cases a GT 740M GDDR5 can end up performing nearly twice as fast as a GT 740M DDR3 laptop. Basically, DDR3 GPUs really shouldn’t be used in anything with more than a 1366x768 resolution display, and frankly 1366x768 should die a fast death – preferably yesterday, if I had my way. DDR3 will continue to be used in the mainstream 800M GPUs, and it appears GDDR5 is no longer even an option (maybe?); not surprisingly, NVIDIA states that the GTX 850M is on average 70% faster than the 840M. And that brings us to the second tier of mobile 800M GPUs: the "mainstream" class.</p><table align=center border=0 cellpadding=0 cellspacing=0 width=625><tbody readability=4><tr readability=2><td align=center class=contentwhite colspan=4><strong>NVIDIA GeForce "Mainstream" 800M Specifications</strong></td></tr><tr><td><strong>Product</strong></td><td><strong>840M</strong></td><td><strong>830M</strong></td><td><strong>820M</strong></td></tr><tr><td><strong>Process</strong></td><td>28nm</td><td>28nm</td><td>28nm</td></tr><tr><td><strong>Architecture</strong></td><td>Maxwell</td><td>Maxwell</td><td>Fermi</td></tr><tr><td><strong>Cores</strong></td><td>?</td><td>?</td><td>96</td></tr><tr><td><strong>GPU Clock</strong></td><td>?</td><td>?</td><td>719-954MHz</td></tr><tr><td><strong>RAM Clock</strong></td><td>?</td><td>?</td><td>2000MHz</td></tr><tr><td><strong>RAM Interface</strong></td><td>64-bit</td><td>64-bit</td><td>64-bit</td></tr><tr><td><strong>RAM Technology</strong></td><td>DDR3</td><td>DDR3</td><td>DDR3</td></tr><tr><td><strong>Maximum RAM</strong></td><td>2GB</td><td>2GB</td><td>2GB</td></tr><tr readability=6><td><strong>Features</strong></td><td>GPU Boost 2.0<br>Optimus<br>PhysX<br>CUDA<br>GFE</td><td>GPU Boost 2.0<br>Optimus<br>PhysX<br>CUDA<br>GFE</td><td>GPU Boost 2.0<br>Optimus<br>PhysX<br>CUDA<br>GFE</td></tr></tbody></table><p>Obviously, NVIDIA is being a little coy with their specifications for these 800M parts. They were good enough to tell us that both the 840M and 830M will use Maxwell-based GPUs, but that’s as far as they would go. I’d guess we’ll see 512 core Maxwell GM107 parts in both of those, although perhaps they might drop another SMX and run with 384 cores on one (or both?) of those; we’ll have to wait and see. The 64-bit memory interface is going to be a pretty severe bottleneck as well, and I’m not sure the new 840M will even be able to consistently outperform the previous generation GT 740M – particularly if the 740M used GDDR5. Actually, scratch that; I’m almost certain a GT 740M GDDR5 solution will be faster than the 840M DDR3, though perhaps not as energy efficient.</p><p>And just in case you don’t particularly care for having a modern GPU, Fermi rides again and is available in the 820M. NVIDIA didn’t disclose specs in the launch information, but this part has already been launched so we know what's in here. Of course, this is Fermi in 2014 so really – who cares? 96 cores is at least better than 48 cores (705M), but NVIDIA is at least flirting with iGPU levels of performance with the 820M. In my book, if you don’t need anything more than an 820M, you probably don’t need the 820M!</p><p>You can see NVIDIA's images/renders of the various chips in the gallery below:</p><p>Wrapping up the specifications overview, NVIDIA was nice and forthcoming with estimates of relative performance. There will likely be exceptions, depending on the game and settings you choose to test, but here’s a nice table summarizing NVIDIA’s estimates:</p><table align=center border=0 cellpadding=0 cellspacing=0 width=500><tbody readability=1><tr readability=2><td align=center class=contentwhite colspan=4><strong>NVIDIA's Performance Estimates for the 800M Series</strong></td></tr><tr><td><strong>GPU</strong></td><td><strong>% Increase Over<br>Next GPU</strong></td><td><strong>% of 820M</strong></td><td><strong>% of GTX 760M</strong></td></tr><tr><td><strong>GTX 880M</strong></td><td>20%</td><td>641%</td><td>227%</td></tr><tr><td><strong>GTX 870M</strong></td><td>35%</td><td>534%</td><td>189%</td></tr><tr><td><strong>GTX 860M</strong></td><td>15%</td><td>396%</td><td>140%</td></tr><tr><td><strong>GTX 850M</strong></td><td>70%</td><td>344%</td><td>122%</td></tr><tr><td><strong>840M</strong></td><td>35%</td><td>203%</td><td>72%</td></tr><tr><td><strong>830M</strong></td><td>50%</td><td>150%</td><td>53%</td></tr><tr><td><strong>820M</strong></td><td>N/A</td><td>100%</td><td>35%</td></tr></tbody></table><p>This is actually a pretty useful set of estimates (assuming it's correct), as it allows us to immediately see that all of the new GTX GPUs should be quite a bit faster than the GTX 760M, which was a fairly decent mobile GPU. We can also see that the gulf between the mainstream and GTX classes remains quite large. I’m still a bit skeptical of the 840M with DDR3 actually delivering a good performance, as a 64-bit interface is a huge bottleneck. Assuming this is again DDR3-2000 (most GPUs with DDR3 top out at DDR3-2000), we’re talking about a feeble 16GB/s of memory bandwidth – that’s lower than what most desktops and laptops now have for system memory, as DDR3-1600 with a 128-bit interface will do 25.6GB/s. Ouch. Of course it will depend on what settings you want to run at; for me, I don’t mind using medium quality in most games, but the low quality settings can often look quite awful.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZIR5f5Nopa%2BhlJ6ubrPEn6arm5VihXF8zGajoqaVqr1ursCtq56qqWKvsLvSrQ%3D%3D</p></section><nav class=post-nav><a class=prev href=./micky-geller-net-worth-2023.html><span>←</span><span>Micky Geller: Net Worth 2023, Death Explained, Obituary, Girlfriend and More</span></a>
<a class=next href=./659277-snoop-dogg-reveals-he-wasnt-a-fan-of-hit-em-up.html><span>Snoop Dogg Reveals He Wasn't A Fan Of &amp;quot;Hit 'Em Up&amp;quot;</span><span>→</span></a></nav></article></main><footer class=footer><p>&copy; 2024 <a href=./></a></p><p>Powered by <a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>️</p></footer><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>